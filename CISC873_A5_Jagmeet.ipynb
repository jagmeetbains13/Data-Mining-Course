{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AlphL2IM_Ij"
   },
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91TpI4jogaA_"
   },
   "source": [
    "**Submitted By: Jagmeet Singh**\n",
    "\n",
    "**Problem Description:** It is a binary classification problem based on the graph data. The task is to predict the anticancer activity of a chemical compound using the chemical structure of the compound. The chemical compound can be positive or negative against lung cancer cell and thus labelled as either 0 or 1. \n",
    "\n",
    "**Data Description:** The data is in the form of graph which represents the chemical structure of the compound. Each sample of data contains information about the atoms and the connections between atoms of the molecule. So in this problem the features are the atoms and connections.\n",
    "\n",
    "**Methods Used:**\n",
    "\n",
    "1. The first step is to read the sdf file to get the information about the atoms and their connectivity in the compound. The atoms are described as nodes and connections are described as edges. The read_sdf method is used to read sdf file and the chemical composition of the compound.\n",
    "\n",
    "2. The nodes(atoms) are given as characters (like \\['O','N','Cl'....]). Thus it is treated as sequence of text data and best way to describe the text data sequence to tokenize the data and then adding the embeddig layer. \n",
    "\n",
    "3. Graph convolutional network is used in this assignment to calculate the probability of the output class. Different methods differ in implementing message passing methods as:\n",
    "\n",
    "* **R-GCN Method**: (Graph convolution layers) Compute new graph states by neural message passing.\n",
    "\n",
    "* **R-GAT Method**: (Relation graph attention network layer) Compute new graph states by neural message passing using attention.\n",
    "\n",
    "* **R-GIN Method**: (Relation Graph Isomorphism Network message propogation layer) Compute new graph states by neural message passing using MLPs for state updates and message computation.\n",
    "\n",
    "* **GGNN Method**: (Gated graph neural network layer) Compute new graph states by neural message passing and gated units on the nodes. This method works best for this problem as given in Aggregation Method 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5DYSxhXM61Z",
    "outputId": "25bc8045-9b06-4d3f-ec1e-27e06bf1ff58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mounting google drive to import data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH8sttOVftve"
   },
   "source": [
    "# Read SDF format data (structured-data format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzUZR456NJ2i"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np   \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#method to read sdf file\n",
    "#the chemical composition of a molecule is saved as SDF(structure data file) file\n",
    "#sdf file store information about position of individual atom\n",
    "#molecules are delimited by $$$$\n",
    "#the atom block lines start with '    ' and have information about atoms(C,O,N,Cl..)\n",
    "#bond block starts with ' ' and contains info about connection between atoms\n",
    "\n",
    "def read_sdf(file):\n",
    "    with open(file, 'r') as rf:   #opening the file in read mode\n",
    "        content = rf.read()       #reading the contents of the file\n",
    "    samples = content.split('$$$$') #splitting the read file by delimiter $$$$ thus splitting each molecule in an array\n",
    "    \n",
    "    #method to read each molecule configuration\n",
    "    #s represents one molecule\n",
    "    def parse_sample(s):\n",
    "        lines = s.splitlines()    #splitting the text data to lines\n",
    "        links = []                #empty array for links\n",
    "        nodes = []                #empty array for nodes\n",
    "        label = 0\n",
    "        for l in lines:           #loop over each line\n",
    "            if l.strip() == '1.0':   #\n",
    "                label = 1\n",
    "            if l.strip() == '-1.0':\n",
    "                label = 0\n",
    "            if l.startswith('    '):  #for Atom block  \n",
    "                feature = l.split()   #splitting line\n",
    "                node = feature[3]     #node feature (atom) as O,C etc.\n",
    "                nodes.append(node)    #appending nodes\n",
    "            elif l.startswith(' '):   #bond block tells about connections between atoms\n",
    "                lnk = l.split()       #splitting line\n",
    "                # edge: (from, to,) (1-based index)\n",
    "                if int(lnk[0]) - 1 < len(nodes):   #\n",
    "                    links.append((   #appending links\n",
    "                        int(lnk[0])-1,   #first atom\n",
    "                        int(lnk[1])-1, # zero-based index #second atom\n",
    "                        # int(lnk[2]) ignore edge weight\n",
    "                    ))\n",
    "        return nodes, np.array(links), label #returning nodes, links and label\n",
    "    \n",
    "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]  #parse_sample for each molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "9e4147debbb9433198025db31ace112f",
      "5bfa382f871e49feb292ab19a89032f5",
      "9e3e61d692de4b828d48fcb664427c49",
      "d59b3af571aa47f388dfe36553dd2df9",
      "df9339ebb6aa44478c77465b02dd9344",
      "0d5d1b55f8e343bb84de382b79894311",
      "4ba86edce2a94f88a60ae52da6bebc96",
      "00e708c4773547a2a5e66472fc5237a1"
     ]
    },
    "id": "bWDSpnISNOBd",
    "outputId": "6f39357e-5b1a-4bc7-e052-2352797f9e32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4147debbb9433198025db31ace112f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25024.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#reading train.sdf file\n",
    "training_set = read_sdf('drive/My Drive/CISC873/A5/train.sdf')\n",
    "\n",
    "#splitting the train data\n",
    "training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "c11bbada7a734e10ae778796fde9feee",
      "f6ae005db9ea42bea9dbf4b2f92747b7",
      "f247b9a918d6410d947f142c9d1af32e",
      "61e6434076f6452f81d3cdfdfd00b13b",
      "37de922bbff04997879841f2eccf81fd",
      "eba61cac26f44995bc16cbbeb8def5af",
      "ed92b06040b642f1837800205b4a79b2",
      "4c86b3ef12274b608165050bcf43041e"
     ]
    },
    "id": "XyqYaQEwNQn3",
    "outputId": "5d4bdccc-d6c7-4de6-f617-6fc87e2f5e53"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11bbada7a734e10ae778796fde9feee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12326.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#reading test file\n",
    "testing_set  = read_sdf('drive/My Drive/CISC873/A5/test_x.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5ijt3CbfzkP"
   },
   "source": [
    "# Visualizing/Inspecting a Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXi103PJxPCG"
   },
   "source": [
    "* Training set contains data for each sample(molecule). Each sample array contains three elements. First element has information about the atoms in text format, second element has information about the connections and third element tells about the label for each molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zK9_sL0sf4B_"
   },
   "outputs": [],
   "source": [
    "#importing libraries for displaying network of molecule\n",
    "!pip install --quiet networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IINvuKUNfdVo"
   },
   "outputs": [],
   "source": [
    "#method to visualize the compound graph\n",
    "#atoms are given as nodes\n",
    "#the connections are defined as edges\n",
    "\n",
    "\n",
    "def visualize(sample):\n",
    "    G=nx.Graph() #initiating an instance of Graph\n",
    "    nodes = sample[0] #atoms as nodes\n",
    "    edges = sample[1] #connections as edges\n",
    "    \n",
    "    labeldict={} #empty dictionary for labels for the nodes\n",
    "    node_color=[] #empty array for each node color\n",
    "    for i,n in enumerate(nodes): #for each node in the sample\n",
    "        G.add_node(i)   #adding node to the graph each node as (0,1,2,3..)\n",
    "        labeldict[i]=n  #dictionary building with [key,value] as [0:'C']\n",
    "        #print(i)\n",
    "        #print(n)\n",
    "        node_color.append(colors[hash(n)%len(colors)]) #color coding\n",
    "\n",
    "    # a list of nodes:\n",
    "    for e in edges: #for each edge\n",
    "        G.add_edge(e[0], e[1]) #adding egde to the graph from one connection to other connection\n",
    "\n",
    "    #drawing the graph with labels for nodes as atoms and connections as edges    \n",
    "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
    "    plt.show()\n",
    "    #returns graph\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "wD29ck7kf-Ni",
    "outputId": "15f7029d-7e9b-4f75-af3f-5cb98179b97f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7ff0e0ff3cc0>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying one sample\n",
    "plt.clf()\n",
    "visualize(training_set[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDSAXrjLNWSm"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxshsJJpk6w5",
    "outputId": "05237a36-8a90-4482-9897-ee3acdc8ccac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([20253,  1017]))"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the labels of the training dataset\n",
    "labelss = []\n",
    "for sam in training_set:\n",
    "  labelss.append(sam[2])\n",
    "np.unique(labelss,return_counts=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMsMGLHIlyW3",
    "outputId": "bc512bad-e366-4a04-9472-d39d946c2c3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([12326]))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the labels of the testing dataset\n",
    "labelss = []\n",
    "for sam in testing_set:\n",
    "  labelss.append(sam[2])\n",
    "np.unique(labelss,return_counts=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMQ5q54813LP"
   },
   "source": [
    "* Tokenizing the nodes(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAn4RG1eNUUZ"
   },
   "outputs": [],
   "source": [
    "#Tokenizer importing \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#vocabulary size\n",
    "max_vocab = 500\n",
    "max_len = 100 # maximum length of the tokenized vector\n",
    "\n",
    "\n",
    "# build vocabulary from training set only for nodes characters\n",
    "all_nodes = [s[0] for s in training_set]\n",
    "\n",
    "#training tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi75xjCENYtH"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "random.seed(0) #random seed\n",
    "\n",
    "\n",
    "#method to prepare single batch set\n",
    "#samples represents the batch of data\n",
    "def prepare_single_batch(samples):\n",
    "    sample_nodes = [s[0] for s in samples]                      #nodes characters array\n",
    "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)   #tokenizing the sample nodes\n",
    "    sample_nodes = pad_sequences(sample_nodes, padding='post')  #pad_sequences for each sample node with post padding\n",
    "    max_nodes_len = np.shape(sample_nodes)[1]                   #maximum length of nodes \n",
    "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)] #defining edges\n",
    "    edges = [e for e in edges if len(e) > 0]\n",
    "\n",
    "    #each \n",
    "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]  #array definition for segmented_ids\n",
    "    \n",
    "    all_nodes = np.reshape(sample_nodes, -1)  #reshaping as 1 vector\n",
    "    all_edges = np.concatenate(edges)         #concatenating all the edges as size [total_edges ,2]\n",
    "\n",
    "    node_to_graph = np.reshape(node_to_graph, -1)\n",
    "    #returns a dictionary of features(data,edges,node2grah) and label\n",
    "    return {\n",
    "        'data': all_nodes,\n",
    "        'edges': all_edges,\n",
    "        'node2grah': node_to_graph,\n",
    "    }, np.array([s[2] for s in samples]) \n",
    "\n",
    "\n",
    "#generating batch with given btch_size\n",
    "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
    "    while True:                 #infinity loop\n",
    "        dataset = list(dataset) #data in the array\n",
    "        if shuffle:             # if shuffle is True\n",
    "            random.shuffle(dataset) #randomly shuffling\n",
    "        l = len(dataset)  #length of dataset\n",
    "        for ndx in range(0, l, batch_size):  #loop for  creating batches from given dataset\n",
    "            batch_samples = dataset[ndx:min(ndx + batch_size, l)] #creating batch samples with given batch_size\n",
    "            yield prepare_single_batch(batch_samples)   #returning a generator with prepared batches\n",
    "        if not repeat:  #breaking loop if repeat is false\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMqjB-9mNbZc"
   },
   "outputs": [],
   "source": [
    "# showing one batch:\n",
    "for train_batch in gen_batch(training_set, batch_size=10):\n",
    "    for k,v in train_batch[0].items():\n",
    "        print(k)        \n",
    "        print(v)\n",
    "        print(\"Shape is \"+str(np.shape(v)))\n",
    "        pass\n",
    "    print('label', train_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RO0B4YaBNeCk",
    "outputId": "9446d755-209d-46a9-99d3-691582454d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.1MB 11.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 194kB 21.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.6MB 20.7MB/s \n",
      "\u001b[?25h  Building wheel for tf2-gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet tf2_gnn\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "\n",
    "#for deep Graph Neural Network\n",
    "from tf2_gnn.layers.gnn import GNN, GNNInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbQGH9dCK0Gx"
   },
   "source": [
    "## Aggregation Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SrqgFfSNfyr",
    "outputId": "d541dc8f-d108-47c3-e4ae-3938c3262af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out Tensor(\"gnn_8/StatefulPartitionedCall:0\", shape=(None, 40), dtype=float32)\n",
      "mean: Tensor(\"SegmentMean_5:0\", shape=(None, 40), dtype=float32)\n",
      "pred: Tensor(\"dense_4/Sigmoid:0\", shape=(None, 1), dtype=float32)\n",
      "Model: \"functional_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Max_8 (TensorFlowOp [()]                 0           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 100)          50000       input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow [()]                 0           tf_op_layer_Max_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "gnn_8 (GNN)                     (None, 40)           35440       embedding_8[0][0]                \n",
      "                                                                 input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "                                                                 tf_op_layer_AddV2_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SegmentMean_5 (Tens [(None, 40)]         0           gnn_8[0][0]                      \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            41          tf_op_layer_SegmentMean_5[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 85,481\n",
      "Trainable params: 85,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#importing tensorflow and other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean #to calculate segmented mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model #layers and model\n",
    "from tensorflow.keras.layers import Embedding, Dense #layers\n",
    "from tensorflow.keras.optimizers import Adam #optimizer\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "To understand the dimensions:\n",
    "Let's assume the batch contains 10 samples of data.\n",
    "The nodes are tokenized using 44 dimension array that is each sample node is of shape [44]\n",
    "Thus 10 samples are of shape [440] after applying get_batch method\n",
    "node2graph is also of shape [440] like [0,0,0,0,0,...,1,1,1,1,....2,2,2,....] each number is repeated 44 times [0,0,0,0,... 44 times]\n",
    "Lets assume edges are of size [257,2]\n",
    "\n",
    "The GNN layer takes a GNNInput named tuple as input, which encapsulates initial node features, adjacency lists, and auxiliary information.\n",
    "\n",
    "'''\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))  #Input layer for nodes (tokenized text data)            eg. [440]\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)     #Input layer for edge data         eg. [257,2]\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) #Input layer for node2graph ids    eg. [440]\n",
    "\n",
    "embeded = Embedding(tokenizer.num_words, 100)(data)  #embedding layer over data with each token embedded as  size vector eg. [440,50]\n",
    "\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1  #calculating number of samples (or min(batch_size,no._of_samples))    eg. 10\n",
    "\n",
    "#gnn_input layer with inputs as defined above\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "#defining hyperparameters for GNN layer\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 40  #defining hidden dimension of the gnn layer\n",
    "\n",
    "#gnn layer with defined hyperparameters\n",
    "gnn_layer = GNN(params)  \n",
    "\n",
    "#gnn output layer \n",
    "gnn_out = gnn_layer(gnn_input) #outpur shape: [data_dimension,hidden layers]   eg. [440,64]\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "\n",
    "#calculating segmented mean based on segment_ids\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )                                    #shape: [batch_size,64]  eg. [10,64]\n",
    "\n",
    "print('mean:', avg)\n",
    "\n",
    "#final dense layer with sigmoid\n",
    "pred = Dense(1, activation='sigmoid')(avg)   #output shape: [batch_size,1] eg. []\n",
    "print('pred:', pred)\n",
    "\n",
    "#building model \n",
    "#inputs are data,edges and node2graph\n",
    "#input: dictionary\n",
    "#output: prediction value from dense layer\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "\n",
    "#printing summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyxEJvnPNoKZ"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzQFSu9WNqSt",
    "outputId": "5b786b27-6aaa-4c6a-f85b-4c14b55503b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.2153 - auc: 0.5667 - val_loss: 0.2554 - val_auc: 0.4687\n",
      "Epoch 2/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2074 - auc: 0.5820 - val_loss: 0.2046 - val_auc: 0.5563\n",
      "Epoch 3/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2093 - auc: 0.5452 - val_loss: 0.2248 - val_auc: 0.5091\n",
      "Epoch 4/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2063 - auc: 0.5550 - val_loss: 0.2346 - val_auc: 0.3853\n",
      "Epoch 5/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2057 - auc: 0.5424 - val_loss: 0.1907 - val_auc: 0.6483\n",
      "Epoch 6/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.2026 - auc: 0.5672 - val_loss: 0.1946 - val_auc: 0.6213\n",
      "Epoch 7/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2065 - auc: 0.5291 - val_loss: 0.2038 - val_auc: 0.5127\n",
      "Epoch 8/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2022 - auc: 0.5387 - val_loss: 0.2262 - val_auc: 0.4477\n",
      "Epoch 9/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.2006 - auc: 0.5319 - val_loss: 0.1921 - val_auc: 0.6192\n",
      "Epoch 10/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1959 - auc: 0.5808 - val_loss: 0.1920 - val_auc: 0.6277\n",
      "Epoch 11/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1919 - auc: 0.6136 - val_loss: 0.1851 - val_auc: 0.6738\n",
      "Epoch 12/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1906 - auc: 0.6110 - val_loss: 0.1901 - val_auc: 0.6578\n",
      "Epoch 13/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1904 - auc: 0.5987 - val_loss: 0.1889 - val_auc: 0.6195\n",
      "Epoch 14/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1873 - auc: 0.6346 - val_loss: 0.1826 - val_auc: 0.6941\n",
      "Epoch 15/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1873 - auc: 0.6382 - val_loss: 0.1854 - val_auc: 0.5856\n",
      "Epoch 16/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1876 - auc: 0.6337 - val_loss: 0.1839 - val_auc: 0.6599\n",
      "Epoch 17/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1863 - auc: 0.6473 - val_loss: 0.1958 - val_auc: 0.5841\n",
      "Epoch 18/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1856 - auc: 0.6508 - val_loss: 0.1822 - val_auc: 0.6693\n",
      "Epoch 19/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1874 - auc: 0.6364 - val_loss: 0.1810 - val_auc: 0.6538\n",
      "Epoch 20/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1871 - auc: 0.6400 - val_loss: 0.1843 - val_auc: 0.6901\n",
      "Epoch 21/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1859 - auc: 0.6529 - val_loss: 0.1916 - val_auc: 0.6454\n",
      "Epoch 22/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1867 - auc: 0.6417 - val_loss: 0.1885 - val_auc: 0.6841\n",
      "Epoch 23/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1857 - auc: 0.6573 - val_loss: 0.1862 - val_auc: 0.6749\n",
      "Epoch 24/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1863 - auc: 0.6510 - val_loss: 0.1822 - val_auc: 0.6761\n",
      "Epoch 25/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1864 - auc: 0.6548 - val_loss: 0.1927 - val_auc: 0.6446\n",
      "Epoch 26/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1874 - auc: 0.6372 - val_loss: 0.1765 - val_auc: 0.6902\n",
      "Epoch 27/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1874 - auc: 0.6322 - val_loss: 0.1864 - val_auc: 0.7158\n",
      "Epoch 28/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1872 - auc: 0.6412 - val_loss: 0.1821 - val_auc: 0.7239\n",
      "Epoch 29/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1878 - auc: 0.6311 - val_loss: 0.1860 - val_auc: 0.6848\n",
      "Epoch 30/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1860 - auc: 0.6544 - val_loss: 0.1828 - val_auc: 0.6738\n",
      "Epoch 31/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1864 - auc: 0.6435 - val_loss: 0.1871 - val_auc: 0.7035\n",
      "Epoch 32/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1859 - auc: 0.6507 - val_loss: 0.1776 - val_auc: 0.7139\n",
      "Epoch 33/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1853 - auc: 0.6516 - val_loss: 0.1823 - val_auc: 0.6468\n",
      "Epoch 34/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1870 - auc: 0.6399 - val_loss: 0.1880 - val_auc: 0.6283\n",
      "Epoch 35/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1887 - auc: 0.6280 - val_loss: 0.1873 - val_auc: 0.6759\n",
      "Epoch 36/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1888 - auc: 0.6264 - val_loss: 0.1933 - val_auc: 0.6333\n",
      "Epoch 37/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1907 - auc: 0.6067 - val_loss: 0.1821 - val_auc: 0.6838\n",
      "Epoch 38/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1883 - auc: 0.6387 - val_loss: 0.1861 - val_auc: 0.6365\n",
      "Epoch 39/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1884 - auc: 0.6290 - val_loss: 0.1859 - val_auc: 0.6994\n",
      "Epoch 40/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1862 - auc: 0.6506 - val_loss: 0.1890 - val_auc: 0.7010\n",
      "Epoch 41/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1861 - auc: 0.6494 - val_loss: 0.1775 - val_auc: 0.7376\n",
      "Epoch 42/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1902 - auc: 0.6219 - val_loss: 0.1982 - val_auc: 0.5966\n",
      "Epoch 43/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1897 - auc: 0.6182 - val_loss: 0.1841 - val_auc: 0.5774\n",
      "Epoch 44/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1882 - auc: 0.6340 - val_loss: 0.1874 - val_auc: 0.7151\n",
      "Epoch 45/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1869 - auc: 0.6401 - val_loss: 0.1853 - val_auc: 0.7125\n",
      "Epoch 46/50\n",
      "2659/2659 [==============================] - 28s 10ms/step - loss: 0.1891 - auc: 0.6185 - val_loss: 0.1823 - val_auc: 0.6767\n",
      "Epoch 47/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1859 - auc: 0.6478 - val_loss: 0.1883 - val_auc: 0.6595\n",
      "Epoch 48/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1857 - auc: 0.6447 - val_loss: 0.1876 - val_auc: 0.6866\n",
      "Epoch 49/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1870 - auc: 0.6458 - val_loss: 0.1836 - val_auc: 0.7214\n",
      "Epoch 50/50\n",
      "2659/2659 [==============================] - 28s 11ms/step - loss: 0.1870 - auc: 0.6469 - val_loss: 0.1797 - val_auc: 0.7012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f344ae9da90>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#math.ceil: returns the smallest integral value greater than the number\n",
    "num_batchs = math.ceil(len(training_set) / batch_size) #no. of batches for training data\n",
    "\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size) #no. of batches for validation data\n",
    "\n",
    "model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=50,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=16, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nV8NG9UQNshz"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(\n",
    "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
    ")\n",
    "y_pred = np.reshape(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gZ0E1RONuTk",
    "outputId": "8826b3f8-6d1e-4133-b22c-6db61aa7f5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12326"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpYpaUDWNwFJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "submission = pd.DataFrame({'label':y_pred})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('sub_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5UoqMtLM6EP"
   },
   "source": [
    "## Aggregation Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vstu_i1lOeUe"
   },
   "outputs": [],
   "source": [
    "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
    "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
    "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgOPbuuDM6EP",
    "outputId": "9ec9780f-044c-4bfb-9a05-d4542ab86fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
      "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
      "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max (TFOpLambda) ()                   0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 75)           37500       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd ()                   0           tf.math.reduce_max[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "gnn (GNN)                       (None, 32)           49568       embedding[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.segment_mean (TFOpLambd (None, 32)           0           gnn[0][0]                        \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            264         tf.math.segment_mean[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            9           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 87,341\n",
      "Trainable params: 87,341\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#importing tensorflow and other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean #to calculate segmented mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model #layers and model\n",
    "from tensorflow.keras.layers import Embedding, Dense #layers\n",
    "from tensorflow.keras.optimizers import Adam #optimizer\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "To understand the dimensions:\n",
    "Let's assume the batch contains 10 samples of data.\n",
    "The nodes are tokenized using 44 dimension array that is each sample node is of shape [44]\n",
    "Thus 10 samples are of shape [440] after applying get_batch method\n",
    "node2graph is also of shape [440] like [0,0,0,0,0,...,1,1,1,1,....2,2,2,....] each number is repeated 44 times [0,0,0,0,... 44 times]\n",
    "Lets assume edges are of size [257,2]\n",
    "\n",
    "The GNN layer takes a GNNInput named tuple as input, which encapsulates initial node features, adjacency lists, and auxiliary information.\n",
    "\n",
    "'''\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))  #Input layer for nodes (tokenized text data)            eg. [440]\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)     #Input layer for edge data         eg. [257,2]\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) #Input layer for node2graph ids    eg. [440]\n",
    "\n",
    "embeded = Embedding(tokenizer.num_words, 75)(data)  #embedding layer over data with each token embedded as  size vector eg. [440,75]\n",
    "\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1  #calculating number of samples (or min(batch_size,no._of_samples))    eg. 10\n",
    "\n",
    "#gnn_input layer with inputs as defined above\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "#defining hyperparameters for GNN layer\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 32 #defining hidden dimension of the gnn layer\n",
    "params[\"message_calculation_class\"] = 'GGNN'\n",
    "#params[\"num_edge_MLP_hidden_layers\"] = 16\n",
    "#gnn layer with defined hyperparameters\n",
    "gnn_layer = GNN(params)  \n",
    "\n",
    "#gnn output layer \n",
    "gnn_out = gnn_layer(gnn_input) #outpur shape: [data_dimension,hidden layers]   eg. [440,32]\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "\n",
    "#calculating segmented mean based on segment_ids\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )                                    #shape: [batch_size,64]  eg. [10,32]\n",
    "\n",
    "print('mean:', avg)\n",
    "\n",
    "#final dense layer with sigmoid\n",
    "fc1 = Dense(8,activation='relu')(avg) #Output [None,8]\n",
    "#fc2 = Dense(64,activation='relu')(fc1)\n",
    "pred = Dense(1, activation='sigmoid')(fc1)   #output shape: [batch_size,1] \n",
    "print('pred:', pred)\n",
    "\n",
    "#building model \n",
    "#inputs are data,edges and node2graph\n",
    "#input: dictionary\n",
    "#output: prediction value from dense layer\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "\n",
    "#printing summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvABWGbNM6ER"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6nZrW_JM6ER",
    "outputId": "ce4e3a12-a4bf-4c4e-f385-48c4ff604d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "333/333 [==============================] - 28s 86ms/step - loss: 0.1846 - auc: 0.6380 - val_loss: 0.1901 - val_auc: 0.7529\n",
      "Epoch 2/2\n",
      "333/333 [==============================] - 28s 85ms/step - loss: 0.1818 - auc: 0.6666 - val_loss: 0.2037 - val_auc: 0.6357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd1ceb0240>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "#math.ceil: returns the smallest integral value greater than the number\n",
    "num_batchs = math.ceil(len(training_set) / batch_size) #no. of batches for training data\n",
    "\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size) #no. of batches for validation data\n",
    "\n",
    "model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=2,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=16, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    "   # callbacks=[\n",
    "    #    tf.keras.callbacks.EarlyStopping(monitor='auc', patience=5, restore_best_weights=True,mode='max')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMdw6N9MM6ES"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(\n",
    "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
    ")\n",
    "y_pred = np.reshape(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtGLRJboM6ES",
    "outputId": "8826b3f8-6d1e-4133-b22c-6db61aa7f5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12326"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeEKR6Z7M6ES"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "submission = pd.DataFrame({'label':y_pred})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('sub_47.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOe19iOFNEyH"
   },
   "source": [
    "## Aggregation Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgvHDGroNn3O"
   },
   "outputs": [],
   "source": [
    "from  tf2_gnn.layers.message_passing import RGAT,  MessagePassing, MessagePassingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8Pq6k_tNEyI",
    "outputId": "9c8f1e81-71e7-4494-b735-761fdd08c878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_out Tensor(\"gnn_8/StatefulPartitionedCall:0\", shape=(None, 12), dtype=float32)\n",
      "mean: Tensor(\"SegmentMean_4:0\", shape=(None, 12), dtype=float32)\n",
      "pred: Tensor(\"dense_5/Sigmoid:0\", shape=(None, 1), dtype=float32)\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Max_12 (TensorFlowO [()]                 0           input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 100)          50000       input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_12 (TensorFlo [()]                 0           tf_op_layer_Max_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "gnn_8 (GNN)                     (None, 12)           6360        embedding_12[0][0]               \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 tf_op_layer_AddV2_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SegmentMean_4 (Tens [(None, 12)]         0           gnn_8[0][0]                      \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            13          tf_op_layer_SegmentMean_4[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 56,373\n",
      "Trainable params: 56,373\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#importing tensorflow and other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import segment_mean #to calculate segmented mean\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model #layers and model\n",
    "from tensorflow.keras.layers import Embedding, Dense #layers\n",
    "from tensorflow.keras.optimizers import Adam #optimizer\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "To understand the dimensions:\n",
    "Let's assume the batch contains 10 samples of data.\n",
    "The nodes are tokenized using 44 dimension array that is each sample node is of shape [44]\n",
    "Thus 10 samples are of shape [440] after applying get_batch method\n",
    "node2graph is also of shape [440] like [0,0,0,0,0,...,1,1,1,1,....2,2,2,....] each number is repeated 44 times [0,0,0,0,... 44 times]\n",
    "Lets assume edges are of size [257,2]\n",
    "\n",
    "The GNN layer takes a GNNInput named tuple as input, which encapsulates initial node features, adjacency lists, and auxiliary information.\n",
    "\n",
    "'''\n",
    "\n",
    "data = keras.Input(batch_shape=(None,))  #Input layer for nodes (tokenized text data)            eg. [440]\n",
    "\n",
    "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
    "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)     #Input layer for edge data         eg. [257,2]\n",
    "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) #Input layer for node2graph ids    eg. [440]\n",
    "\n",
    "embeded = Embedding(tokenizer.num_words, 100)(data)  #embedding layer over data with each token embedded as  size vector eg. [440,100]\n",
    "\n",
    "\n",
    "# number of graphs (number of samples)\n",
    "num_graph = tf.reduce_max(node2graph)+1  #calculating number of samples (or min(batch_size,no._of_samples))    eg. 10\n",
    "\n",
    "#gnn_input layer with inputs as defined above\n",
    "gnn_input = GNNInput(\n",
    "    node_features=embeded,\n",
    "    adjacency_lists=(edge,),\n",
    "    node_to_graph_map=node2graph, \n",
    "    num_graphs=num_graph,\n",
    ")\n",
    "\n",
    "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
    "#defining hyperparameters for GNN layer\n",
    "params = GNN.get_default_hyperparameters()\n",
    "params[\"hidden_dim\"] = 12 #defining hidden dimension of the gnn layer\n",
    "params[\"message_calculation_class\"] = 'rgat'\n",
    "#params[\"num_layers\"] = 4\n",
    "params[\"num_heads\"] = 3\n",
    "\n",
    "#params['num_aggr_MLP_hidden_layers'] = 12\n",
    "#gnn layer with defined hyperparameters\n",
    "gnn_layer = GNN(params)  \n",
    "\n",
    "#gnn output layer \n",
    "gnn_out = gnn_layer(gnn_input) #outpur shape: [data_dimension,hidden layers]   eg. [440,12]\n",
    "\n",
    "print('gnn_out', gnn_out)           \n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
    "\n",
    "#calculating segmented mean based on segment_ids\n",
    "avg = segment_mean(\n",
    "    data=gnn_out,\n",
    "    segment_ids=node2graph\n",
    "    )                                    #shape: [batch_size,64]  eg. [10,12]\n",
    "\n",
    "print('mean:', avg)\n",
    "\n",
    "#final dense layer with sigmoid\n",
    "pred = Dense(1, activation='sigmoid')(avg)   #output shape: [batch_size,1] \n",
    "print('pred:', pred)\n",
    "\n",
    "#building model \n",
    "#inputs are data,edges and node2graph\n",
    "#input: dictionary\n",
    "#output: prediction value from dense layer\n",
    "model = Model(\n",
    "    inputs={\n",
    "        'data': data, \n",
    "        'edges': edge,\n",
    "        'node2grah': node2graph,\n",
    "    },\n",
    "    outputs=pred\n",
    ")\n",
    "\n",
    "#printing summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gSSs7dQNEyI"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjFahRyDNEyI",
    "outputId": "cdb65486-2931-4637-d04e-89b6720b9c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.2352 - auc: 0.4877 - val_loss: 0.2311 - val_auc: 0.5506\n",
      "Epoch 2/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1971 - auc: 0.5894 - val_loss: 0.2046 - val_auc: 0.6024\n",
      "Epoch 3/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1930 - auc: 0.6156 - val_loss: 0.1955 - val_auc: 0.6414\n",
      "Epoch 4/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1889 - auc: 0.6449 - val_loss: 0.1975 - val_auc: 0.6452\n",
      "Epoch 5/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1856 - auc: 0.6730 - val_loss: 0.1864 - val_auc: 0.6921\n",
      "Epoch 6/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1850 - auc: 0.6715 - val_loss: 0.1947 - val_auc: 0.6509\n",
      "Epoch 7/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1818 - auc: 0.6896 - val_loss: 0.1988 - val_auc: 0.6480\n",
      "Epoch 8/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1832 - auc: 0.6801 - val_loss: 0.1914 - val_auc: 0.6815\n",
      "Epoch 9/30\n",
      "1330/1330 [==============================] - 21s 16ms/step - loss: 0.1821 - auc: 0.6914 - val_loss: 0.1838 - val_auc: 0.6988\n",
      "Epoch 10/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1829 - auc: 0.6780 - val_loss: 0.1884 - val_auc: 0.6807\n",
      "Epoch 11/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1811 - auc: 0.6805 - val_loss: 0.1886 - val_auc: 0.6906\n",
      "Epoch 12/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1832 - auc: 0.6764 - val_loss: 0.1908 - val_auc: 0.6772\n",
      "Epoch 13/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1812 - auc: 0.6842 - val_loss: 0.2023 - val_auc: 0.6332\n",
      "Epoch 14/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1808 - auc: 0.6862 - val_loss: 0.1839 - val_auc: 0.6604\n",
      "Epoch 15/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1802 - auc: 0.6886 - val_loss: 0.1960 - val_auc: 0.6910\n",
      "Epoch 16/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1810 - auc: 0.6754 - val_loss: 0.2054 - val_auc: 0.6434\n",
      "Epoch 17/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1816 - auc: 0.6769 - val_loss: 0.1854 - val_auc: 0.6752\n",
      "Epoch 18/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1791 - auc: 0.6909 - val_loss: 0.1954 - val_auc: 0.6229\n",
      "Epoch 19/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1795 - auc: 0.6883 - val_loss: 0.1928 - val_auc: 0.6979\n",
      "Epoch 20/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1800 - auc: 0.6869 - val_loss: 0.1870 - val_auc: 0.6866\n",
      "Epoch 21/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1797 - auc: 0.6806 - val_loss: 0.1843 - val_auc: 0.7108\n",
      "Epoch 22/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1782 - auc: 0.6988 - val_loss: 0.1884 - val_auc: 0.6774\n",
      "Epoch 23/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1810 - auc: 0.6799 - val_loss: 0.1967 - val_auc: 0.6004\n",
      "Epoch 24/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1799 - auc: 0.6849 - val_loss: 0.1965 - val_auc: 0.6891\n",
      "Epoch 25/30\n",
      "1330/1330 [==============================] - 21s 15ms/step - loss: 0.1809 - auc: 0.6690 - val_loss: 0.1777 - val_auc: 0.7121\n",
      "Epoch 26/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1805 - auc: 0.6682 - val_loss: 0.1892 - val_auc: 0.7086\n",
      "Epoch 27/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1791 - auc: 0.6857 - val_loss: 0.1737 - val_auc: 0.7124\n",
      "Epoch 28/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1786 - auc: 0.6848 - val_loss: 0.1969 - val_auc: 0.6723\n",
      "Epoch 29/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1784 - auc: 0.6885 - val_loss: 0.1869 - val_auc: 0.6911\n",
      "Epoch 30/30\n",
      "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1788 - auc: 0.6926 - val_loss: 0.1828 - val_auc: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fad45994390>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#math.ceil: returns the smallest integral value greater than the number\n",
    "num_batchs = math.ceil(len(training_set) / batch_size) #no. of batches for training data\n",
    "\n",
    "num_batchs_validation = math.ceil(len(validation_set) / batch_size) #no. of batches for validation data\n",
    "\n",
    "model.fit(\n",
    "    gen_batch(\n",
    "        training_set, batch_size=batch_size, repeat=True\n",
    "    ),\n",
    "    steps_per_epoch=num_batchs,\n",
    "    epochs=30,\n",
    "    validation_data=gen_batch(\n",
    "        validation_set, batch_size=16, repeat=True\n",
    "    ),\n",
    "    validation_steps=num_batchs_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhIumRt6NEyJ"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(\n",
    "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
    ")\n",
    "y_pred = np.reshape(y_pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTp1JOejNEyJ",
    "outputId": "8826b3f8-6d1e-4133-b22c-6db61aa7f5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12326"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feS567IINEyJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "submission = pd.DataFrame({'label':y_pred})\n",
    "submission.index.name = 'id'\n",
    "submission.to_csv('sub_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfT6HSL0uFnt"
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcOhJvVBuIKH"
   },
   "source": [
    "### Ques 1: Based on the provided template, describe the format of the input file (sdf file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54js7B4jmmom"
   },
   "source": [
    "Ans: The input file is structure data file (SDF). It contains information about the chemical composition of a molecule.\n",
    "SDF file store information about position of individual atom in the chemical compound and also tells about the connections. Different molecules are delimited by '\\$\\$\\$\\$' expression. \n",
    "\n",
    "Each sample/molecule starts with header which tells about the name/title of the compound. Other sections includes information about Atom count, version number, connections etc. Atom block tells about the elements of the compound. Bond block block tells about the bonding structure of the compound. These both blocks are used in this assignment to get information about the compound and saving them in form of edges and nodes. Each node is the atom given in the chemical molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVfi91uVuQR-"
   },
   "source": [
    "### Ques 2: What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size?)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWmY-R3bIOqm"
   },
   "source": [
    "Ans: The input tensors in this network are:\n",
    "\n",
    "1. **data**: The data contains the nodes of the chemical compound in the tokenized form. Nodes for each compound are extracted, then they are tokenized using the tokenizer and finally padding is done using pad_sequence method. The shape for each batch is **\\[batch_size*max_len_nodes]**, where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
    "\n",
    "2. **edge**: edge is the input tensor which carries information about connections between atoms. The shape of edge is **\\[sum_of_all_edges,2]**. The sum_of_all_edges represents the sum(no. of edges of each sample) of the batch_size. For example in a batch of 3 samples, the number of edges in sample 1: 21, sample 2: 20 and sample 3: 40. So the size of edge tensor would be \\[81,2].\n",
    "\n",
    "3. **node2graph**: It is the input tensor which is used for segmented mean and contains information about segmented ids. The shape for each batch is **\\[batch_size*max_len_nodes]**, where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq6f3QQkuVoA"
   },
   "source": [
    "### Ques 3: For each dim of gnn_out, what does it represent? For each dim of avg, what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsaqcSEKkZp0"
   },
   "source": [
    "Ans: \n",
    "\n",
    "**gnn_out**: The gnn_out is of shape \\[batch_size_node_dimension,hidden layers], where batch_size_node_dimension is the dimension of the input data (node) vector (dimension of tokenized vector for the complete batch). It represents the aggregation output of the model for each hidden layer.\n",
    "\n",
    "**avg**: Average takes the segmented mean of the gnn_out based on the segmented ids. For each sample in the batch_size, the output of gnn_out is \\[tokenized_vector_dimension, hidden_layers]. Each sample has one segment id. Thus the segment_mean takes the mean of all the output data in the gnn_out output and represents one sample with one number for each hidden layer. The final output of the avg tensor is of shape \\[batch_size, hidden_layer]. It is a way of collecting information for each sample and representing it in the form of mean data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdkVJqgqubbC"
   },
   "source": [
    "### Ques 4: What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8VYV6GoPscW"
   },
   "source": [
    "Ans: **segment_mean** takes the mean of the data which have same segmented ids. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCHEzWRvQYK_"
   },
   "source": [
    "**reduce_mean:** computes the mean of elements across dimensions of a tensor given the arguments.\n",
    "\n",
    "**pred:** The final output (pred) tells about the probability of a chemical compound to be active for the cancer cell or not. The shape of pred is \\[batch_size,1]. Thus for each sample, the final output is a number which represents the probability associated with each chemical compound about its activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWSNCyb9ueh9"
   },
   "source": [
    "### Ques 5: What is the motivation / theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YbSMAF1CACG"
   },
   "source": [
    "Ans: \n",
    "\n",
    "The default template implements the default setting of the number of layers in the gcn network. The default layer are **4** as given in the documentaion. The default message passing method is rgcn (Graph convolution layers). Using multiple gcn helps in incorporating all the graph complexity properly and thus creates a better model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CISC873_A5_Jagmeet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00e708c4773547a2a5e66472fc5237a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d5d1b55f8e343bb84de382b79894311": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37de922bbff04997879841f2eccf81fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4ba86edce2a94f88a60ae52da6bebc96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c86b3ef12274b608165050bcf43041e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bfa382f871e49feb292ab19a89032f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61e6434076f6452f81d3cdfdfd00b13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c86b3ef12274b608165050bcf43041e",
      "placeholder": "​",
      "style": "IPY_MODEL_ed92b06040b642f1837800205b4a79b2",
      "value": " 12326/12326 [00:08&lt;00:00, 1512.50it/s]"
     }
    },
    "9e3e61d692de4b828d48fcb664427c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d5d1b55f8e343bb84de382b79894311",
      "max": 25024,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df9339ebb6aa44478c77465b02dd9344",
      "value": 25024
     }
    },
    "9e4147debbb9433198025db31ace112f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e3e61d692de4b828d48fcb664427c49",
       "IPY_MODEL_d59b3af571aa47f388dfe36553dd2df9"
      ],
      "layout": "IPY_MODEL_5bfa382f871e49feb292ab19a89032f5"
     }
    },
    "c11bbada7a734e10ae778796fde9feee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f247b9a918d6410d947f142c9d1af32e",
       "IPY_MODEL_61e6434076f6452f81d3cdfdfd00b13b"
      ],
      "layout": "IPY_MODEL_f6ae005db9ea42bea9dbf4b2f92747b7"
     }
    },
    "d59b3af571aa47f388dfe36553dd2df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00e708c4773547a2a5e66472fc5237a1",
      "placeholder": "​",
      "style": "IPY_MODEL_4ba86edce2a94f88a60ae52da6bebc96",
      "value": " 25024/25024 [00:11&lt;00:00, 2217.05it/s]"
     }
    },
    "df9339ebb6aa44478c77465b02dd9344": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "eba61cac26f44995bc16cbbeb8def5af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed92b06040b642f1837800205b4a79b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f247b9a918d6410d947f142c9d1af32e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eba61cac26f44995bc16cbbeb8def5af",
      "max": 12326,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37de922bbff04997879841f2eccf81fd",
      "value": 12326
     }
    },
    "f6ae005db9ea42bea9dbf4b2f92747b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
